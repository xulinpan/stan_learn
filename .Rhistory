install.packages("rstan")
install.packages("ggplot2")
install.packages("rstan")
install.packages("brms")
install.packages("shiny")
install.packages("tidyverse")
install.packages("ggplot")
install.packages("MASS")
R --version
--version
x <- c(1,23)
x
x[2]
x[3] <- 45
x
for i in range(20):
for (i in range(5)){}
for (i in range(5)){}
for (i in range(5)){x[i]=i}
x
x <- 1:5
x[2:4]
x[-2]
x
x[[2,4]]
x[[2 4]]
x[c(2.4)]
x[c(2,4)]
paste("x",1:2,sep="")
paste("x",1:3,sep="")
x <- 1:4
x
x[3] <- NULL
x[5] <- NULL
sex <- c("f","m")
fsex <- factor(sex)
fsex
str(fsex)
fsex <- factor(sex,levels = 0:1,ordered = FALSE)
fsex
sex
fsex
rm(list=ls())
setwd("D:/My Textbook/Machine Learning with R/Datasets")
str(iris)
library(MASS)
fit <- lda(Species~.,data=iris)
fit
plot(fit,abbrev=TRUE,col=as.numeric(iris$Species))  # Abbreviate variable names
set.seed(1)
train_index <- sample(150,100)
train <- iris[train_index,]
test <- iris[-train_index,]
fit <- lda(Species~.,data=train)
pred <- predict(fit)
names(pred)
prob_train <- pred$posterior
head(prob_train)
class_train <- pred$class
table(Predicted=class_train,Actual=train$Species)
cat("LDA Training Error Rate =",mean(class_train!=train$Species),"\n")
class_test <- predict(fit,newdata=test)$class
table(Predicted=class_test,Actual=test$Species)
cat("LDA Test Error Rate =",mean(class_test!=test$Species),"\n")
class_test <- predict(fit,newdata=test)$class
table(Predicted=class_test,Actual=test$Species)
cat("LDA Test Error Rate =",mean(class_test!=test$Species),"\n")
fit <- qda(Species~.,data=iris)
fit
set.seed(1)
train_index <- sample(150,100)
train <- iris[train_index,]
test <- iris[-train_index,]
fit <- qda(Species~.,data=train)
class_train <- predict(fit)$class
table(Predicted=class_train,Actual=train$Species)
cat("QDA Training Error Rate =",mean(class_train!=train$Species),"\n")
class_test <- predict(fit,newdata=test)$class
table(Predicted=class_test,Actual=test$Species)
cat("QDA Test Error Rate =",mean(class_test!=test$Species),"\n")
rm(list=ls())
setwd("D:/My Textbook/Machine Learning with R/Datasets")
# install.packages("ElemStatLearn")
library(ElemStatLearn)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
# install.packages("ElemStatLearn")
library(ElemStatLearn)
data(spam)
str(spam)
head(spam,3)
table(spam$spam)
# install.packages("e1071")
library(e1071)
install.packages("e1071")
# install.packages("e1071")
library(e1071)
set.seed(1)
train_index <- sample(4601, 3601)
train <- spam[train_index,]
test <- spam[-train_index,]
table(train$spam)
prop.table(table(train$spam))   # table by proportion
table(test$spam)
prop.table(table(test$spam))    # table by proportion
fit <- naiveBayes(spam~.,data=train)
pred_train <- predict(fit,newdata = train)
table <- table(Predicted=pred_train,Actual=train$spam)
table
train_error <- (table[2,1]+table[1,2])/nrow(train)
train_error
pred_test <- predict(fit,newdata = test)
table <- table(Predicted=pred_test,Actual=test$spam)
table
test_error <- (table[2,1]+table[1,2])/nrow(test)
test_error
fit <- naiveBayes(spam~.,data=train,laplace=1)
pred_test <- predict(fit,newdata = test)
table <- table(Predicted=pred_test,Actual=test$spam)
table
test_error <- (table[2,1]+table[1,2])/nrow(test)
test_error
str(spam)
head(spam,3)
table(spam$spam)
# install.packages("e1071")
library(e1071)
set.seed(1)
train_index <- sample(4601, 3601)
train <- spam[train_index,]
test <- spam[-train_index,]
table(train$spam)
prop.table(table(train$spam))   # table by proportion
table(test$spam)
prop.table(table(test$spam))    # table by proportion
fit <- naiveBayes(spam~.,data=train)
pred_train <- predict(fit,newdata = train)
table <- table(Predicted=pred_train,Actual=train$spam)
table
train_error <- (table[2,1]+table[1,2])/nrow(train)
train_error
pred_test <- predict(fit,newdata = test)
table <- table(Predicted=pred_test,Actual=test$spam)
table
test_error <- (table[2,1]+table[1,2])/nrow(test)
test_error
fit <- naiveBayes(spam~.,data=train,laplace=1)
pred_test <- predict(fit,newdata = test)
table <- table(Predicted=pred_test,Actual=test$spam)
table
test_error <- (table[2,1]+table[1,2])/nrow(test)
test_error
rm(list=ls())
setwd("D:/My Textbook/Machine Learning with R/Datasets")
library(MASS)
str(Boston)
dim(Boston)
set.seed(123)
train <-  sample(nrow(Boston), nrow(Boston)/2)
# install.packages("gbm")
library(gbm)
install.packages("lmer")
install.packages("lme4")
knitr::opts_chunk$set(echo = TRUE)
G <- matrix(c(24^2,0,0,10^2),nrow = 2)
G
rm(list = ls())
set.seed(5432)
J <- 15
N <- 30
test.df <- data.frame(unit = sort(rep(c(1:N),J)),
J = rep(c(1:J),N), x = rnorm(n = J*N))
View(test.df)
beta <- 3 + 0.2*rnorm(N)
beta
View(test.df)
test.df$beta <- beta[test.df$unit]
View(test.df)
test.df$y <- 1 + test.df$x*test.df$beta + 0.75*rnorm(n = J*N)
View(test.df)
head(test.df,18)
# Seperate regressions
beta.hat <- list()
for (i in 1:N) {
unit.lm <- lm(y ~ x,data = subset(test.df, unit == 1))
beta.hat[i] <- coef(unit.lm)[2]
}
beta.hat <- as.numeric(beta.hat)
beta.hat
test.df <- data.frame(unit = sort(rep(c(1:N),J)),
J = rep(c(1:J),N), x = rnorm(n = J*N))
beta <- 3 + 0.2*rnorm(N)
test.df$beta <- beta[test.df$unit]
test.df$y <- 1 + test.df$x*test.df$beta + 0.75*rnorm(n = J*N)
head(test.df,18)
# Seperate regressions
beta.hat <- list()
for (i in 1:N) {
unit.lm <- lm(y ~ x,data = subset(test.df, unit == 1))
beta.hat[i] <- coef(unit.lm)[2]
}
beta.hat <- as.numeric(beta.hat)
beta.hat
beta.hat <- as.numeric(beta.hat)
par(mfrow = c(2,1))
hist(beta,main = "Histogram of Actual SLopes", col = "blue",
xlab = expression(beta[i]), cex.axis = 1.5, cex.lab = 1.5,
breaks = seq(from = 2.4, to = 3.6, by = 0.1))
hist(as.numeric(beta.hat), main = "Histogram of Estimated Slopes",
xlab = expression(hat(beta)[i]), col = "blue", cex.axis =1.5,
cex.lab = 1.5, breaks = seq(from = 2.4, to = 3.6, by = 0.1))
# Seperate regressions
beta.hat <- list()
for (i in 1:N) {
unit.lm <- lm(y ~ x,data = subset(test.df, unit == i))
beta.hat[i] <- coef(unit.lm)[2]
}
beta.hat <- as.numeric(beta.hat)
par(mfrow = c(2,1))
hist(beta,main = "Histogram of Actual SLopes", col = "blue",
xlab = expression(beta[i]), cex.axis = 1.5, cex.lab = 1.5,
breaks = seq(from = 2.4, to = 3.6, by = 0.1))
hist(as.numeric(beta.hat), main = "Histogram of Estimated Slopes",
xlab = expression(hat(beta)[i]), col = "blue", cex.axis =1.5,
cex.lab = 1.5, breaks = seq(from = 2.4, to = 3.6, by = 0.1))
hist(as.numeric(beta.hat), main = "Histogram of Estimated Slopes",
xlab = expression(hat(beta)[i]), col = "blue", cex.axis =1.5,
cex.lab = 1.5, breaks = seq(from = 2.4, to = 3.6, by = 0.1))
hist(beta.hat, main = "Histogram of Estimated Slopes",
xlab = expression(hat(beta)[i]), col = "blue", cex.axis =1.5,
cex.lab = 1.5, breaks = seq(from = 2.4, to = 3.6, by = 0.1))
rm(list = ls())
set.seed(5432)
J <- 15
N <- 30
test.df <- data.frame(unit = sort(rep(c(1:N),J)),
J = rep(c(1:J),N), x = rnorm(n = J*N))
beta <- 3 + 0.2*rnorm(N)
test.df$beta <- beta[test.df$unit]
test.df$y <- 1 + test.df$x*test.df$beta + 0.75*rnorm(n = J*N)
head(test.df,18)
# Seperate regressions
beta.hat <- list()
for (i in 1:N) {
unit.lm <- lm(y ~ x,data = subset(test.df, unit == i))
beta.hat[i] <- coef(unit.lm)[2]
}
beta.hat <- as.numeric(beta.hat)
beta.hat
par(mfrow = c(2,1))
hist(beta,main = "Histogram of Actual SLopes", col = "blue",
xlab = expression(beta[i]), cex.axis = 1.5, cex.lab = 1.5,
breaks = seq(from = 2.4, to = 3.6, by = 0.1))
hist(as.numeric(beta.hat), main = "Histogram of Estimated Slopes",
xlab = expression(hat(beta)[i]), col = "blue", cex.axis =1.5,
cex.lab = 1.5, breaks = seq(from = 2.4, to = 3.6, by = 0.1))
View(test.df)
install.packages("EpiModel", dependencies = TRUE)
install.packages("BiocManager")
BiocManager::install('recount')
## Browse the vignetets for a quick description of how to use the package
library('recount')
browseVignettes('recount')
## Download the RangedSummarizedExperiment object at the gene level for study SP009615
url <- download_study('SRP009615')
## Install recount from Bioconductor
install.packages("BiocManager")
BiocManager::install('recount')
## Browse the vignetets for a quick description of how to use the package
library('recount')
browseVignettes('recount')
## Find a project of interest
project_info <- abstract_search('GSE32465')
project_info
# Download the gene-level RangedSummarizedExperiment data
download_study(project_info$project)
getwd()
setwd("/Users/xulin/Documents/mytutorial/stan")
getwd()
library(rstan)
lookup(rnorm)
#lookup(rnorm)
options(mc.cores = parallel::detectCores()) # parallelize
rstan_options(auto_write = TRUE)  # store compiled stan model
schools.data <- list(
n = 8,
y = c(28,  8, -3,  7, -1,  1, 18, 12),
sigma = c(15, 10, 16, 11,  9, 11, 10, 18)
)
fit1 <- stan(
file = "schools.stan",  # Stan program
data = schools.data,    # named list of data
chains = 4,             # number of Markov chains
warmup = 1000,          # number of warmup iterations per chain
iter = 2000,            # total number of iterations per chain
refresh = 1000          # show progress every 'refresh' iterations
)
print(fit1)
# specify the params to plot via pars
plot(fit1, pars = "theta")
# retrieve the samples
samples <- extract(fit1, permuted = TRUE) # 1000 samples per parameter
mu <- samples$mu  # samples of mu only
print(mu)
tau
# diagnostics:
traceplot(fit1, pars = c("mu", "tau"), inc_warmup = TRUE, nrow = 2)
library(shinystan)
launch_shinystan(fit1)
